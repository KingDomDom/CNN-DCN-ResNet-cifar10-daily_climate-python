{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "2.1.1+cu121\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "使用VS Code+jupyter notebook编译\n",
    "使用Nvidia RTX3060 GPU进行训练\n",
    "作者:张伟业\n",
    "'''\n",
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "print(torch.cuda.is_available())\n",
    "print(torch.__version__)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入所需要的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import tarfile\n",
    "import os\n",
    "import os.path as osp\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机种子设定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义 CNN 网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 4, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(4, 8, 3)\n",
    "        self.fc1 = nn.Linear(8 * 6 * 6, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 8 * 6 * 6)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义深度卷积网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepConvNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.relu4 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(256)\n",
    "        self.relu5 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv6 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(256)\n",
    "        self.relu6 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.bn1(self.conv1(x)))\n",
    "        x = self.relu2(self.bn2(self.conv2(x)))\n",
    "        x = self.relu3(self.bn3(self.conv3(x)))\n",
    "        x = self.relu4(self.bn4(self.conv4(x)))\n",
    "        x = self.relu5(self.bn5(self.conv5(x)))\n",
    "        x = self.relu6(self.bn6(self.conv6(x)))\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义 CNN 加 Rsidual Block 的新网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.downsample = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResidualNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ResidualNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.residual_block1 = ResidualBlock(32, 32)\n",
    "        self.residual_block2 = ResidualBlock(32, 64, stride=2)\n",
    "        self.residual_block3 = ResidualBlock(64, 128, stride=2)\n",
    "        self.residual_block4 = ResidualBlock(128, 256, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "\n",
    "        x = self.residual_block1(x)\n",
    "        x = self.residual_block2(x)\n",
    "        x = self.residual_block3(x)\n",
    "        x = self.residual_block4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "超参数设定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "BATCH_SIZE = 128  # 每个训练批次中包含的样本数量\n",
    "NUM_EPOCHS = 10  # 训练迭代的总轮数\n",
    "EVAL_INTERVAL = 2  # 用于设定多少个 epoch 后进行模型性能评估\n",
    "SAVE_DIR = './log'  # 保存训练日志和模型检查点的目录\n",
    "\n",
    "# Optimizer\n",
    "LEARNING_RATE = 1e-1  # 学习率，用于控制权重更新的步长\n",
    "MOMENTUM = 0.9  # 动量参数，用于加速权重更新\n",
    "STEP = 10  # 学习率调度的步数\n",
    "GAMMA = 0.1  # 学习率调度的衰减率 \n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集加载与处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义数据集的URL和存储路径\n",
    "url = 'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n",
    "data_dir = './dataset-cifar10'\n",
    "\n",
    "# 创建存储路径（如果不存在）\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# 下载并解压缩数据集\n",
    "filename = url.split('/')[-1]\n",
    "filepath = os.path.join(data_dir, filename)\n",
    "\n",
    "if not os.path.exists(filepath):\n",
    "    urllib.request.urlretrieve(url, filepath)\n",
    "    tar = tarfile.open(filepath, 'r:gz')\n",
    "    tar.extractall(data_dir)\n",
    "    tar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练数据的图像预处理操作：\n",
    "transform_cifar10_train = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# 定义测试数据的图像预处理操作：\n",
    "transform_cifar10_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "#定义训练和测试的数据集以及数据加载器\n",
    "train_set = datasets.CIFAR10(root=data_dir, train=True,\n",
    "                                        download=False, transform=transform_cifar10_train)\n",
    "\n",
    "train_dataloader = DataLoader(train_set, batch_size=BATCH_SIZE,\n",
    "                                            shuffle=True, num_workers=2)\n",
    "\n",
    "test_set = datasets.CIFAR10(root=data_dir, train=False,\n",
    "                                        download=False, transform=transform_cifar10_test)\n",
    "\n",
    "test_dataloader = DataLoader(test_set, batch_size=BATCH_SIZE,\n",
    "                                            shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(model, image, target):\n",
    "    output = model(image)\n",
    "    loss_fn =nn.CrossEntropyLoss()\n",
    "    loss = loss_fn(output , target)\n",
    "    return output, loss\n",
    "\n",
    "def test_batch(model, image, target):\n",
    "    output = model(image)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    loss = loss_fn(output, target)\n",
    "    return output, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型选择与训练-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic = True\n",
    "model = ConvNet()\n",
    "model.to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP, gamma=GAMMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10 Train Loss: 0.0138 Acc: 0.3536\n",
      "Epoch: 2/10 Train Loss: 0.0128 Acc: 0.4115\n",
      "Begin test......\n",
      "Test Loss: 0.0123 Acc: 0.4498\n",
      "Epoch: 3/10 Train Loss: 0.0125 Acc: 0.4322\n",
      "Epoch: 4/10 Train Loss: 0.0124 Acc: 0.4368\n",
      "Begin test......\n",
      "Test Loss: 0.0130 Acc: 0.4108\n",
      "Epoch: 5/10 Train Loss: 0.0122 Acc: 0.4465\n",
      "Epoch: 6/10 Train Loss: 0.0119 Acc: 0.4626\n",
      "Begin test......\n",
      "Test Loss: 0.0123 Acc: 0.4632\n",
      "Epoch: 7/10 Train Loss: 0.0120 Acc: 0.4561\n",
      "Epoch: 8/10 Train Loss: 0.0121 Acc: 0.4559\n",
      "Begin test......\n",
      "Test Loss: 0.0128 Acc: 0.4437\n",
      "Epoch: 9/10 Train Loss: 0.0120 Acc: 0.4646\n",
      "Epoch: 10/10 Train Loss: 0.0120 Acc: 0.4617\n",
      "Begin test......\n",
      "Test Loss: 0.0129 Acc: 0.4356\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()  # 设置模型为训练模式\n",
    "    torch.cuda.empty_cache()  # 清空GPU缓存\n",
    "\n",
    "    # 训练阶段\n",
    "    running_cls_loss = 0.0  # 用于存储每个batch的训练损失\n",
    "    running_cls_corrects = 0  # 用于存储每个batch的训练正确预测的样本数\n",
    "\n",
    "    # 遍历训练数据集的每个batch\n",
    "    for batch_idx, (image, target) in enumerate(train_dataloader):\n",
    "\n",
    "        image = image.to(device)  # 将图像数据移动到GPU（如果可用）\n",
    "        target = target.to(device)  # 将标签数据移动到GPU（如果可用）\n",
    "\n",
    "        # 训练模型并获取输出和损失\n",
    "        outputs, loss = train_batch(model, image, target)\n",
    "        _, preds = torch.max(outputs, 1)  # 获取预测的类别\n",
    "\n",
    "        loss_data = loss.data.item()\n",
    "        if np.isnan(loss_data):\n",
    "            raise ValueError('loss is nan while training')  # 检查损失是否为NaN\n",
    "        running_cls_loss += loss.item()\n",
    "        running_cls_corrects += torch.sum(preds == target.data)  # 统计正确预测的样本数\n",
    "\n",
    "        loss.backward()  # 反向传播计算梯度\n",
    "        optimizer.step()  # 使用优化器更新模型参数\n",
    "        optimizer.zero_grad()  # 清空梯度\n",
    "\n",
    "    # 计算当前epoch的平均损失和准确度\n",
    "    epoch_loss = running_cls_loss / len(train_set)\n",
    "    epoch_acc = running_cls_corrects.double() / len(train_set)\n",
    "\n",
    "    print(f'Epoch: {epoch + 1}/{NUM_EPOCHS} Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "\n",
    "    # 调整学习率\n",
    "    scheduler.step()  # 调整学习率策略\n",
    "\n",
    "    # 测试阶段\n",
    "    if (epoch + 1) % EVAL_INTERVAL == 0 or (epoch + 1) == NUM_EPOCHS:\n",
    "        print('Begin test......')\n",
    "        model.eval()  # 设置模型为评估模式\n",
    "\n",
    "        val_loss = 0.0  # 用于存储测试损失\n",
    "        val_corrects = 0  # 用于存储测试正确预测的样本数\n",
    "\n",
    "        # 遍历测试数据集的每个batch\n",
    "        for batch_idx, (image, target) in enumerate(test_dataloader):\n",
    "            image = image.to(device)  # 将图像数据移动到GPU（如果可用）\n",
    "            target = target.to(device)  # 将标签数据移动到GPU（如果可用）\n",
    "\n",
    "            # 测试模型并获取输出和损失\n",
    "            outputs, loss = test_batch(model, image, target)\n",
    "            _, preds = torch.max(outputs, 1)  # 获取预测的类别\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_corrects += torch.sum(preds == target.data)  # 统计正确预测的样本数\n",
    "\n",
    "        val_loss = val_loss / len(test_set)  # 计算平均测试损失\n",
    "        val_acc = val_corrects.double() / len(test_set)  # 计算测试准确度\n",
    "        print(f'Test Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
    "\n",
    "        # 在最后一个epoch保存模型\n",
    "        if (epoch + 1) == NUM_EPOCHS:\n",
    "\n",
    "            state = {\n",
    "                'state_dict': model.state_dict(),\n",
    "                'acc': epoch_acc,\n",
    "                'epoch': (epoch + 1),\n",
    "            }\n",
    "\n",
    "            # 检查目录是否存在，如果不存在则创建\n",
    "            if not os.path.exists(SAVE_DIR):\n",
    "                os.makedirs(SAVE_DIR)\n",
    "\n",
    "            # 保存模型状态\n",
    "            torch.save(state, osp.join(SAVE_DIR, 'checkpoint_%s.pth' % (str(epoch + 1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型选择与训练-DeepCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic = True\n",
    "model = DeepConvNet()\n",
    "model.to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP, gamma=GAMMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10 Train Loss: 0.0122 Acc: 0.4224\n",
      "Epoch: 2/10 Train Loss: 0.0090 Acc: 0.5840\n",
      "Begin test......\n",
      "Test Loss: 0.0114 Acc: 0.5184\n",
      "Epoch: 3/10 Train Loss: 0.0075 Acc: 0.6586\n",
      "Epoch: 4/10 Train Loss: 0.0065 Acc: 0.7071\n",
      "Begin test......\n",
      "Test Loss: 0.0109 Acc: 0.5761\n",
      "Epoch: 5/10 Train Loss: 0.0058 Acc: 0.7404\n",
      "Epoch: 6/10 Train Loss: 0.0051 Acc: 0.7720\n",
      "Begin test......\n",
      "Test Loss: 0.0086 Acc: 0.6578\n",
      "Epoch: 7/10 Train Loss: 0.0047 Acc: 0.7912\n",
      "Epoch: 8/10 Train Loss: 0.0042 Acc: 0.8130\n",
      "Begin test......\n",
      "Test Loss: 0.0054 Acc: 0.7632\n",
      "Epoch: 9/10 Train Loss: 0.0038 Acc: 0.8304\n",
      "Epoch: 10/10 Train Loss: 0.0034 Acc: 0.8479\n",
      "Begin test......\n",
      "Test Loss: 0.0060 Acc: 0.7584\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()  # 设置模型为训练模式\n",
    "    torch.cuda.empty_cache()  # 清空GPU缓存\n",
    "\n",
    "    # 训练阶段\n",
    "    running_cls_loss = 0.0  # 用于存储每个batch的训练损失\n",
    "    running_cls_corrects = 0  # 用于存储每个batch的训练正确预测的样本数\n",
    "\n",
    "    # 遍历训练数据集的每个batch\n",
    "    for batch_idx, (image, target) in enumerate(train_dataloader):\n",
    "\n",
    "        image = image.to(device)  # 将图像数据移动到GPU（如果可用）\n",
    "        target = target.to(device)  # 将标签数据移动到GPU（如果可用）\n",
    "\n",
    "        # 训练模型并获取输出和损失\n",
    "        outputs, loss = train_batch(model, image, target)\n",
    "        _, preds = torch.max(outputs, 1)  # 获取预测的类别\n",
    "\n",
    "        loss_data = loss.data.item()\n",
    "        if np.isnan(loss_data):\n",
    "            raise ValueError('loss is nan while training')  # 检查损失是否为NaN\n",
    "        running_cls_loss += loss.item()\n",
    "        running_cls_corrects += torch.sum(preds == target.data)  # 统计正确预测的样本数\n",
    "\n",
    "        loss.backward()  # 反向传播计算梯度\n",
    "        optimizer.step()  # 使用优化器更新模型参数\n",
    "        optimizer.zero_grad()  # 清空梯度\n",
    "\n",
    "    # 计算当前epoch的平均损失和准确度\n",
    "    epoch_loss = running_cls_loss / len(train_set)\n",
    "    epoch_acc = running_cls_corrects.double() / len(train_set)\n",
    "\n",
    "    print(f'Epoch: {epoch + 1}/{NUM_EPOCHS} Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "\n",
    "    # 调整学习率\n",
    "    scheduler.step()  # 调整学习率策略\n",
    "\n",
    "    # 测试阶段\n",
    "    if (epoch + 1) % EVAL_INTERVAL == 0 or (epoch + 1) == NUM_EPOCHS:\n",
    "        print('Begin test......')\n",
    "        model.eval()  # 设置模型为评估模式\n",
    "\n",
    "        val_loss = 0.0  # 用于存储测试损失\n",
    "        val_corrects = 0  # 用于存储测试正确预测的样本数\n",
    "\n",
    "        # 遍历测试数据集的每个batch\n",
    "        for batch_idx, (image, target) in enumerate(test_dataloader):\n",
    "            image = image.to(device)  # 将图像数据移动到GPU（如果可用）\n",
    "            target = target.to(device)  # 将标签数据移动到GPU（如果可用）\n",
    "\n",
    "            # 测试模型并获取输出和损失\n",
    "            outputs, loss = test_batch(model, image, target)\n",
    "            _, preds = torch.max(outputs, 1)  # 获取预测的类别\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_corrects += torch.sum(preds == target.data)  # 统计正确预测的样本数\n",
    "\n",
    "        val_loss = val_loss / len(test_set)  # 计算平均测试损失\n",
    "        val_acc = val_corrects.double() / len(test_set)  # 计算测试准确度\n",
    "        print(f'Test Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
    "\n",
    "        # 在最后一个epoch保存模型\n",
    "        if (epoch + 1) == NUM_EPOCHS:\n",
    "\n",
    "            state = {\n",
    "                'state_dict': model.state_dict(),\n",
    "                'acc': epoch_acc,\n",
    "                'epoch': (epoch + 1),\n",
    "            }\n",
    "\n",
    "            # 检查目录是否存在，如果不存在则创建\n",
    "            if not os.path.exists(SAVE_DIR):\n",
    "                os.makedirs(SAVE_DIR)\n",
    "\n",
    "            # 保存模型状态\n",
    "            torch.save(state, osp.join(SAVE_DIR, 'checkpoint_%s.pth' % (str(epoch + 1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型选择与训练-ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic = True\n",
    "model = ResidualNet()\n",
    "model.to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP, gamma=GAMMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10 Train Loss: 0.0108 Acc: 0.4970\n",
      "Epoch: 2/10 Train Loss: 0.0069 Acc: 0.6848\n",
      "Begin test......\n",
      "Test Loss: 0.0073 Acc: 0.6839\n",
      "Epoch: 3/10 Train Loss: 0.0051 Acc: 0.7682\n",
      "Epoch: 4/10 Train Loss: 0.0040 Acc: 0.8205\n",
      "Begin test......\n",
      "Test Loss: 0.0055 Acc: 0.7637\n",
      "Epoch: 5/10 Train Loss: 0.0031 Acc: 0.8608\n",
      "Epoch: 6/10 Train Loss: 0.0023 Acc: 0.8965\n",
      "Begin test......\n",
      "Test Loss: 0.0053 Acc: 0.7905\n",
      "Epoch: 7/10 Train Loss: 0.0017 Acc: 0.9227\n",
      "Epoch: 8/10 Train Loss: 0.0012 Acc: 0.9475\n",
      "Begin test......\n",
      "Test Loss: 0.0064 Acc: 0.7819\n",
      "Epoch: 9/10 Train Loss: 0.0008 Acc: 0.9635\n",
      "Epoch: 10/10 Train Loss: 0.0005 Acc: 0.9788\n",
      "Begin test......\n",
      "Test Loss: 0.0073 Acc: 0.7873\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()  # 设置模型为训练模式\n",
    "    torch.cuda.empty_cache()  # 清空GPU缓存\n",
    "\n",
    "    # 训练阶段\n",
    "    running_cls_loss = 0.0  # 用于存储每个batch的训练损失\n",
    "    running_cls_corrects = 0  # 用于存储每个batch的训练正确预测的样本数\n",
    "\n",
    "    # 遍历训练数据集的每个batch\n",
    "    for batch_idx, (image, target) in enumerate(train_dataloader):\n",
    "\n",
    "        image = image.to(device)  # 将图像数据移动到GPU（如果可用）\n",
    "        target = target.to(device)  # 将标签数据移动到GPU（如果可用）\n",
    "\n",
    "        # 训练模型并获取输出和损失\n",
    "        outputs, loss = train_batch(model, image, target)\n",
    "        _, preds = torch.max(outputs, 1)  # 获取预测的类别\n",
    "\n",
    "        loss_data = loss.data.item()\n",
    "        if np.isnan(loss_data):\n",
    "            raise ValueError('loss is nan while training')  # 检查损失是否为NaN\n",
    "        running_cls_loss += loss.item()\n",
    "        running_cls_corrects += torch.sum(preds == target.data)  # 统计正确预测的样本数\n",
    "\n",
    "        loss.backward()  # 反向传播计算梯度\n",
    "        optimizer.step()  # 使用优化器更新模型参数\n",
    "        optimizer.zero_grad()  # 清空梯度\n",
    "\n",
    "    # 计算当前epoch的平均损失和准确度\n",
    "    epoch_loss = running_cls_loss / len(train_set)\n",
    "    epoch_acc = running_cls_corrects.double() / len(train_set)\n",
    "\n",
    "    print(f'Epoch: {epoch + 1}/{NUM_EPOCHS} Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "\n",
    "    # 调整学习率\n",
    "    scheduler.step()  # 调整学习率策略\n",
    "\n",
    "    # 测试阶段\n",
    "    if (epoch + 1) % EVAL_INTERVAL == 0 or (epoch + 1) == NUM_EPOCHS:\n",
    "        print('Begin test......')\n",
    "        model.eval()  # 设置模型为评估模式\n",
    "\n",
    "        val_loss = 0.0  # 用于存储测试损失\n",
    "        val_corrects = 0  # 用于存储测试正确预测的样本数\n",
    "\n",
    "        # 遍历测试数据集的每个batch\n",
    "        for batch_idx, (image, target) in enumerate(test_dataloader):\n",
    "            image = image.to(device)  # 将图像数据移动到GPU（如果可用）\n",
    "            target = target.to(device)  # 将标签数据移动到GPU（如果可用）\n",
    "\n",
    "            # 测试模型并获取输出和损失\n",
    "            outputs, loss = test_batch(model, image, target)\n",
    "            _, preds = torch.max(outputs, 1)  # 获取预测的类别\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_corrects += torch.sum(preds == target.data)  # 统计正确预测的样本数\n",
    "\n",
    "        val_loss = val_loss / len(test_set)  # 计算平均测试损失\n",
    "        val_acc = val_corrects.double() / len(test_set)  # 计算测试准确度\n",
    "        print(f'Test Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
    "\n",
    "        # 在最后一个epoch保存模型\n",
    "        if (epoch + 1) == NUM_EPOCHS:\n",
    "\n",
    "            state = {\n",
    "                'state_dict': model.state_dict(),\n",
    "                'acc': epoch_acc,\n",
    "                'epoch': (epoch + 1),\n",
    "            }\n",
    "\n",
    "            # 检查目录是否存在，如果不存在则创建\n",
    "            if not os.path.exists(SAVE_DIR):\n",
    "                os.makedirs(SAVE_DIR)\n",
    "\n",
    "            # 保存模型状态\n",
    "            torch.save(state, osp.join(SAVE_DIR, 'checkpoint_%s.pth' % (str(epoch + 1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集加载与处理-daily climate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义数据集的URL和存储路径\n",
    "url = 'https://www.kaggle.com/datasets/sumanthvrao/daily-climate-time-series-data'\n",
    "data_dir = './dataset-climate'\n",
    "\n",
    "# 创建存储路径（如果不存在）\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# 下载并解压缩数据集\n",
    "filename = url.split('/')[-1]\n",
    "filepath = os.path.join(data_dir, filename)\n",
    "\n",
    "if not os.path.exists(filepath):\n",
    "    urllib.request.urlretrieve(url, filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>meantemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>meanpressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>84.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1015.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>2.980000</td>\n",
       "      <td>1017.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>7.166667</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>4.633333</td>\n",
       "      <td>1018.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>71.333333</td>\n",
       "      <td>1.233333</td>\n",
       "      <td>1017.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>86.833333</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>1016.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   meantemp   humidity  wind_speed  meanpressure\n",
       "0  2013-01-01  10.000000  84.500000    0.000000   1015.666667\n",
       "1  2013-01-02   7.400000  92.000000    2.980000   1017.800000\n",
       "2  2013-01-03   7.166667  87.000000    4.633333   1018.666667\n",
       "3  2013-01-04   8.666667  71.333333    1.233333   1017.166667\n",
       "4  2013-01-05   6.000000  86.833333    3.700000   1016.500000"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('dataset-climate/DailyDelhiClimateTrain.csv')\n",
    "test_df = pd.read_csv('dataset-climate/DailyDelhiClimateTest.csv')\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理后的训练集数据\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meantemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>meanpressure</th>\n",
       "      <th>humidity_pressure_ratio</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>84.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1015.666667</td>\n",
       "      <td>0.083197</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.400000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>2.980000</td>\n",
       "      <td>1017.800000</td>\n",
       "      <td>0.090391</td>\n",
       "      <td>01</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.166667</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>4.633333</td>\n",
       "      <td>1018.666667</td>\n",
       "      <td>0.085406</td>\n",
       "      <td>01</td>\n",
       "      <td>03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.666667</td>\n",
       "      <td>71.333333</td>\n",
       "      <td>1.233333</td>\n",
       "      <td>1017.166667</td>\n",
       "      <td>0.070129</td>\n",
       "      <td>01</td>\n",
       "      <td>04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>86.833333</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>1016.500000</td>\n",
       "      <td>0.085424</td>\n",
       "      <td>01</td>\n",
       "      <td>05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    meantemp   humidity  wind_speed  meanpressure  humidity_pressure_ratio  \\\n",
       "0  10.000000  84.500000    0.000000   1015.666667                 0.083197   \n",
       "1   7.400000  92.000000    2.980000   1017.800000                 0.090391   \n",
       "2   7.166667  87.000000    4.633333   1018.666667                 0.085406   \n",
       "3   8.666667  71.333333    1.233333   1017.166667                 0.070129   \n",
       "4   6.000000  86.833333    3.700000   1016.500000                 0.085424   \n",
       "\n",
       "  month day  \n",
       "0    01  01  \n",
       "1    01  02  \n",
       "2    01  03  \n",
       "3    01  04  \n",
       "4    01  05  "
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def humidity_pressure_ratio(df):\n",
    "    df['humidity_pressure_ratio'] = df['humidity'] / df['meanpressure']\n",
    "    return df\n",
    "\n",
    "def get_date_columns(date):\n",
    "    year, month, day = date.split('-')\n",
    "    return (year, month, day)\n",
    "\n",
    "train_df = humidity_pressure_ratio(train_df)\n",
    "test_df = humidity_pressure_ratio(test_df)\n",
    "\n",
    "tr_date_cols = train_df['date'].apply(get_date_columns)\n",
    "te_date_cols = test_df['date'].apply(get_date_columns)\n",
    "\n",
    "train_df[['year', 'month', 'day']] = pd.DataFrame(tr_date_cols.tolist(), index=train_df.index)\n",
    "test_df[['year', 'month', 'day']] = pd.DataFrame(te_date_cols.tolist(), index=test_df.index)\n",
    "\n",
    "train_df = train_df.drop('date',axis=1)\n",
    "train_df = train_df.drop('year',axis=1)\n",
    "print('处理后的训练集数据')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_timeseries = train_df[['month', 'day', 'humidity', 'wind_speed', 'meanpressure', 'humidity_pressure_ratio', 'meantemp']].values.astype('float32')\n",
    "te_timeseries = test_df[['month', 'day',  'humidity', 'wind_speed', 'meanpressure', 'humidity_pressure_ratio', 'meantemp']].values.astype('float32')\n",
    "\n",
    "new = pd.concat([train_df, test_df], axis=0).reset_index().drop('index', axis=1)\n",
    "new_timeseries = new[['month', 'day',  'humidity', 'wind_speed', 'meanpressure',  'humidity_pressure_ratio', 'meantemp']].values.astype('float32')\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "tr_timeseries = scaler.fit_transform(tr_timeseries)\n",
    "te_timeseries = scaler.transform(te_timeseries)\n",
    "\n",
    "def create_dataset(dataset, lookback):\n",
    "    X, y = [], []\n",
    "    for i in range(len(dataset)-lookback):\n",
    "        feature = dataset[:,:6][i:i+lookback]\n",
    "        target = dataset[:, 6][i:i+lookback]\n",
    "        X.append(feature)\n",
    "        y.append(target)\n",
    "    return torch.tensor(X), torch.tensor(y)\n",
    "\n",
    "lookback = 7\n",
    "\n",
    "train, test = tr_timeseries, te_timeseries\n",
    "X_train, y_train = create_dataset(train, lookback=lookback)\n",
    "X_test, y_test = create_dataset(test, lookback=lookback)\n",
    "\n",
    "X_train, X_test = X_train, X_test\n",
    "y_train, y_test = y_train, y_test\n",
    "\n",
    "loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_train, y_train),\n",
    "                         batch_size = 8, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size = 6, \n",
    "                            num_layers = 2,\n",
    "                            hidden_size = 128,  \n",
    "                            batch_first = True, \n",
    "                            bidirectional= True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.linear1 = nn.Linear(128*2, 64) \n",
    "        self.linear2 = nn.Linear(64, 8) \n",
    "        self.output_linear = nn.Linear(8, 1)\n",
    "        \n",
    "    def forward(self, x):  \n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.output_linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMModel()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 1e-3, weight_decay = 1e-5)\n",
    "loss_fn = nn.MSELoss()\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10, verbose=True)\n",
    "Epoch = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 /200 : train RMSE:  0.16631314 : test RMSE 0.13590318\n",
      "Epoch 20 /200 : train RMSE:  0.060520027 : test RMSE 0.09534419\n",
      "Epoch 00023: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 00034: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 40 /200 : train RMSE:  0.0616768 : test RMSE 0.08492934\n",
      "Epoch 00045: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 00056: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch 60 /200 : train RMSE:  0.055089902 : test RMSE 0.08253997\n",
      "Epoch 00067: reducing learning rate of group 0 to 3.1250e-05.\n",
      "Epoch 00078: reducing learning rate of group 0 to 1.5625e-05.\n",
      "Epoch 80 /200 : train RMSE:  0.054498214 : test RMSE 0.08075174\n",
      "Epoch 00089: reducing learning rate of group 0 to 7.8125e-06.\n",
      "Epoch 00100: reducing learning rate of group 0 to 3.9063e-06.\n",
      "Epoch 100 /200 : train RMSE:  0.054426435 : test RMSE 0.080931954\n",
      "Epoch 00111: reducing learning rate of group 0 to 1.9531e-06.\n",
      "Epoch 120 /200 : train RMSE:  0.05438379 : test RMSE 0.08070246\n",
      "Epoch 00122: reducing learning rate of group 0 to 9.7656e-07.\n",
      "Epoch 00133: reducing learning rate of group 0 to 4.8828e-07.\n",
      "Epoch 140 /200 : train RMSE:  0.05437545 : test RMSE 0.08086379\n",
      "Epoch 00144: reducing learning rate of group 0 to 2.4414e-07.\n",
      "Epoch 00155: reducing learning rate of group 0 to 1.2207e-07.\n",
      "Epoch 160 /200 : train RMSE:  0.054374766 : test RMSE 0.08085917\n",
      "Epoch 00166: reducing learning rate of group 0 to 6.1035e-08.\n",
      "Epoch 00177: reducing learning rate of group 0 to 3.0518e-08.\n",
      "Epoch 180 /200 : train RMSE:  0.054374576 : test RMSE 0.08085682\n",
      "Epoch 00188: reducing learning rate of group 0 to 1.5259e-08.\n",
      "Epoch 200 /200 : train RMSE:  0.054374542 : test RMSE 0.08085557\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(Epoch+1):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in loader:\n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_fn(y_pred.squeeze(), y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_train) \n",
    "        train_rmse = np.sqrt(loss_fn(y_pred, y_train.unsqueeze(2)))\n",
    "        train_preds = y_pred.clone().detach().cpu().numpy()\n",
    "        \n",
    "        y_pred = model(X_test) \n",
    "        test_rmse = np.sqrt(loss_fn(y_pred, y_test.unsqueeze(2)))\n",
    "        test_preds = y_pred.clone().detach().cpu().numpy()\n",
    "        \n",
    "        scheduler.step(test_rmse)\n",
    "    if epoch % 20 == 0:\n",
    "        print('Epoch', epoch,'/200', ': train RMSE: ', train_rmse.numpy(), ': test RMSE', test_rmse.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
